{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "3a) \n",
    "From Task 2d, you are to use the common-voice mp3 files \n",
    "- under cv-valid-train and cv-valid-train.csv for finetuning train dataset. \n",
    "\n",
    "Write a python jupyter notebook called cv-train-2a.ipynb for this task, using\n",
    "either TensorFlow or PyTorch. \n",
    "\n",
    "You are to split the dataset into 70-30 ratio where 30% is kept for training validation. \n",
    "\n",
    "You are to list down your explanation for your chosen:\n",
    "- preprocessing, \n",
    "- tokenizer, \n",
    "- feature extraction and \n",
    "- pipeline processes (including hyperparameters selected). \n",
    "\n",
    "\n",
    "You are also required to visualise the training and validation metrics and explain your interpretation of these visualisations.\n",
    "\n",
    "3b) \n",
    "Rename your fine-tuned AI model: wav2vec2-large-960h-cv.\n",
    "\n",
    "\n",
    "3c) \n",
    "Within your jupyter notebook, cv-train-2a.ipynb, in task 2d, use your\n",
    "fine-tuned AI model to transcribe the common-voice mp3 files under cv-valid-test and compare the generated text against cv-valid-test.csv. \n",
    "Log your overall performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import os \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Audio Loading\n",
    "import librosa \n",
    "\n",
    "# Modelling\n",
    "import torch \n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/common_voice/cv-valid-train/cv-valid-t...</td>\n",
       "      <td>learn to recognize omens and follow them the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/common_voice/cv-valid-train/cv-valid-t...</td>\n",
       "      <td>everything in the universe evolved he said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/common_voice/cv-valid-train/cv-valid-t...</td>\n",
       "      <td>you came so that you could learn about your dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/common_voice/cv-valid-train/cv-valid-t...</td>\n",
       "      <td>so now i fear nothing because it was those ome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/common_voice/cv-valid-train/cv-valid-t...</td>\n",
       "      <td>if you start your emails with greetings let me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195771</th>\n",
       "      <td>../data/common_voice/cv-valid-train/cv-valid-t...</td>\n",
       "      <td>the englishman said nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195772</th>\n",
       "      <td>../data/common_voice/cv-valid-train/cv-valid-t...</td>\n",
       "      <td>the irish man sipped his tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195773</th>\n",
       "      <td>../data/common_voice/cv-valid-train/cv-valid-t...</td>\n",
       "      <td>what do you know about that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195774</th>\n",
       "      <td>../data/common_voice/cv-valid-train/cv-valid-t...</td>\n",
       "      <td>the phone rang while she was awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195775</th>\n",
       "      <td>../data/common_voice/cv-valid-train/cv-valid-t...</td>\n",
       "      <td>among these people were a couple of cyclists a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195776 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file_path  \\\n",
       "0       ../data/common_voice/cv-valid-train/cv-valid-t...   \n",
       "1       ../data/common_voice/cv-valid-train/cv-valid-t...   \n",
       "2       ../data/common_voice/cv-valid-train/cv-valid-t...   \n",
       "3       ../data/common_voice/cv-valid-train/cv-valid-t...   \n",
       "4       ../data/common_voice/cv-valid-train/cv-valid-t...   \n",
       "...                                                   ...   \n",
       "195771  ../data/common_voice/cv-valid-train/cv-valid-t...   \n",
       "195772  ../data/common_voice/cv-valid-train/cv-valid-t...   \n",
       "195773  ../data/common_voice/cv-valid-train/cv-valid-t...   \n",
       "195774  ../data/common_voice/cv-valid-train/cv-valid-t...   \n",
       "195775  ../data/common_voice/cv-valid-train/cv-valid-t...   \n",
       "\n",
       "                                                     text  \n",
       "0       learn to recognize omens and follow them the o...  \n",
       "1              everything in the universe evolved he said  \n",
       "2       you came so that you could learn about your dr...  \n",
       "3       so now i fear nothing because it was those ome...  \n",
       "4       if you start your emails with greetings let me...  \n",
       "...                                                   ...  \n",
       "195771                        the englishman said nothing  \n",
       "195772                       the irish man sipped his tea  \n",
       "195773                        what do you know about that  \n",
       "195774                 the phone rang while she was awake  \n",
       "195775  among these people were a couple of cyclists a...  \n",
       "\n",
       "[195776 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "df = pd.read_csv(\"../data/common_voice/cv-valid-train.csv\")\n",
    "\n",
    "# Create filepath col to audiofiles \n",
    "df['file_path'] = df['filename'].apply(lambda x: os.path.join(\"../data/common_voice/cv-valid-train\", x))\n",
    "\n",
    "# Remove unnecessary columns + assume the 'text' col is the ground truth labels\n",
    "df_subset = df[['file_path', 'text']]\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((137043, 2), (58733, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the dataset\n",
    "train_df, val_df = train_test_split(df_subset, test_size=0.3, random_state=42)\n",
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file_path    ../data/common_voice/cv-valid-train/cv-valid-t...\n",
       "text         learn to recognize omens and follow them the o...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = df_subset.loc[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/common_voice/cv-valid-train/cv-valid-train/sample-000000.mp3'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['file_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandyscrub/Documents/NUS/Y4S2/HTX/xData/new2/technical_test/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0005, -0.0005, -0.0005,  ...,  0.0010,  0.0084,  0.0085]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "librosa_sample_mp3_input, librosa_sample_mp3_sample_rate = librosa.load(sample['file_path'], sr=16000)\n",
    "\n",
    "# pad input values and return pt tensor\n",
    "input_values = processor(librosa_sample_mp3_input, sampling_rate=16000, return_tensors=\"pt\", padding='longest').input_values\n",
    "input_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 65664])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0005, -0.0005, -0.0005,  ...,  0.0010,  0.0084,  0.0085])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PreTrainedTokenizerBase.from_pretrained() missing 1 required positional argument: 'pretrained_model_name_or_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Wav2Vec2CTCTokenizer\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m tokenizer = \u001b[43mWav2Vec2CTCTokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43munk_token\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m[UNK]\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_token\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m[PAD]\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_delimiter_token\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m|\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: PreTrainedTokenizerBase.from_pretrained() missing 1 required positional argument: 'pretrained_model_name_or_path'"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer\n",
    "\n",
    "tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SeamlessM4TFeatureExtractor\n",
    "\n",
    "feature_extractor = SeamlessM4TFeatureExtractor(feature_size=80, num_mel_bins=80, sampling_rate=16000, padding_value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2BertProcessor\n",
    "\n",
    "processor = Wav2Vec2BertProcessor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SeamlessM4TFeatureExtractor\n",
    "\n",
    "feature_extractor = SeamlessM4TFeatureExtractor.from_pretrained(\"facebook/w2v-bert-2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor)\n",
    "\n",
    "# pad input values and return pt tensor\n",
    "input_values = processor(librosa_sample_mp3_input, sampling_rate=16000, return_tensors=\"pt\", padding='longest').input_values\n",
    "input_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing, Tokenizing and Feature Extraction \n",
    "\n",
    "# Audio Loading\n",
    "def load_audio(file_path, target_sr=16000):\n",
    "    waveform, sr = librosa.load(file_path, sr=target_sr)\n",
    "    return waveform \n",
    "\n",
    "# Tokenizer and Feature Extraction \n",
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating PyTorch Dataset class \n",
    "class ASRDataset(Dataset):\n",
    "    def __init__(self, dataframe, processor):\n",
    "        self.data = dataframe\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        audio = load_audio(row['file_path'])\n",
    "        # input_values = self.processor(audio, sampling_rate=16000, return_tensors=\"pt\", padding='longest').input_values[0]\n",
    "        # tokenize\n",
    "        input_values = self.processor(audio, sampling_rate=16000, return_tensors=\"pt\", padding='longest').input_values\n",
    "        \n",
    "        # retrieve logits\n",
    "        logits = model(input_values).logits\n",
    "\n",
    "        # take argmax and decode\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        transcription = processor.batch_decode(predicted_ids)[0]\n",
    "        \n",
    "        # with self.processor.as_target_processor():\n",
    "        #     labels = self.processor(row['transcription'], return_tensors=\"pt\").input_ids[0]\n",
    "        return {\"input_values\": input_values, \"transcription\": transcription}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ASRDataset(train_df, processor)\n",
    "val_dataset = ASRDataset(val_df, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_values': tensor([[-0.0005, -0.0005, -0.0005,  ..., -0.0001,  0.0007,  0.0010]]),\n",
       " 'transcription': 'AT THE FIRST GLANCE IT WAS DEALLY NOT VERY EXCITED'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Metric to assess model on:\n",
    "- Word Error Rate (WER)\n",
    "- Character Error Rate (CER)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "      <th>duration</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35234</th>\n",
       "      <td>cv-valid-train/sample-035234.mp3</td>\n",
       "      <td>at the first glance it was really not very exc...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../data/common_voice/cv-valid-train/cv-valid-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168647</th>\n",
       "      <td>cv-valid-train/sample-168647.mp3</td>\n",
       "      <td>dense clouds of smoke or dust can be seen thro...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>thirties</td>\n",
       "      <td>female</td>\n",
       "      <td>us</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../data/common_voice/cv-valid-train/cv-valid-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163199</th>\n",
       "      <td>cv-valid-train/sample-163199.mp3</td>\n",
       "      <td>the boy preferred wine</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../data/common_voice/cv-valid-train/cv-valid-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27555</th>\n",
       "      <td>cv-valid-train/sample-027555.mp3</td>\n",
       "      <td>the men climbed the hill and they were tired w...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../data/common_voice/cv-valid-train/cv-valid-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34896</th>\n",
       "      <td>cv-valid-train/sample-034896.mp3</td>\n",
       "      <td>the night was warm and i was thirsty</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>fifties</td>\n",
       "      <td>female</td>\n",
       "      <td>australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../data/common_voice/cv-valid-train/cv-valid-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119879</th>\n",
       "      <td>cv-valid-train/sample-119879.mp3</td>\n",
       "      <td>the boy observed in silence the progress of th...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>fourties</td>\n",
       "      <td>male</td>\n",
       "      <td>newzealand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../data/common_voice/cv-valid-train/cv-valid-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103694</th>\n",
       "      <td>cv-valid-train/sample-103694.mp3</td>\n",
       "      <td>we'd better forget it</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>us</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../data/common_voice/cv-valid-train/cv-valid-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131932</th>\n",
       "      <td>cv-valid-train/sample-131932.mp3</td>\n",
       "      <td>air was either entering or escaping at the rim...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>teens</td>\n",
       "      <td>male</td>\n",
       "      <td>australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../data/common_voice/cv-valid-train/cv-valid-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146867</th>\n",
       "      <td>cv-valid-train/sample-146867.mp3</td>\n",
       "      <td>as soon as he saw me among the crowd he called...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../data/common_voice/cv-valid-train/cv-valid-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121958</th>\n",
       "      <td>cv-valid-train/sample-121958.mp3</td>\n",
       "      <td>two days later the merchant spoke to the boy a...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../data/common_voice/cv-valid-train/cv-valid-t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137043 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                filename  \\\n",
       "35234   cv-valid-train/sample-035234.mp3   \n",
       "168647  cv-valid-train/sample-168647.mp3   \n",
       "163199  cv-valid-train/sample-163199.mp3   \n",
       "27555   cv-valid-train/sample-027555.mp3   \n",
       "34896   cv-valid-train/sample-034896.mp3   \n",
       "...                                  ...   \n",
       "119879  cv-valid-train/sample-119879.mp3   \n",
       "103694  cv-valid-train/sample-103694.mp3   \n",
       "131932  cv-valid-train/sample-131932.mp3   \n",
       "146867  cv-valid-train/sample-146867.mp3   \n",
       "121958  cv-valid-train/sample-121958.mp3   \n",
       "\n",
       "                                                     text  up_votes  \\\n",
       "35234   at the first glance it was really not very exc...         3   \n",
       "168647  dense clouds of smoke or dust can be seen thro...         4   \n",
       "163199                             the boy preferred wine         1   \n",
       "27555   the men climbed the hill and they were tired w...         3   \n",
       "34896                the night was warm and i was thirsty         5   \n",
       "...                                                   ...       ...   \n",
       "119879  the boy observed in silence the progress of th...         3   \n",
       "103694                              we'd better forget it         1   \n",
       "131932  air was either entering or escaping at the rim...         4   \n",
       "146867  as soon as he saw me among the crowd he called...         2   \n",
       "121958  two days later the merchant spoke to the boy a...         2   \n",
       "\n",
       "        down_votes       age  gender      accent  duration  \\\n",
       "35234            1       NaN     NaN         NaN       NaN   \n",
       "168647           1  thirties  female          us       NaN   \n",
       "163199           0       NaN     NaN         NaN       NaN   \n",
       "27555            0       NaN     NaN         NaN       NaN   \n",
       "34896            0   fifties  female   australia       NaN   \n",
       "...            ...       ...     ...         ...       ...   \n",
       "119879           0  fourties    male  newzealand       NaN   \n",
       "103694           0  twenties    male          us       NaN   \n",
       "131932           0     teens    male   australia       NaN   \n",
       "146867           1       NaN     NaN         NaN       NaN   \n",
       "121958           1  twenties    male         NaN       NaN   \n",
       "\n",
       "                                                file_path  \n",
       "35234   ../data/common_voice/cv-valid-train/cv-valid-t...  \n",
       "168647  ../data/common_voice/cv-valid-train/cv-valid-t...  \n",
       "163199  ../data/common_voice/cv-valid-train/cv-valid-t...  \n",
       "27555   ../data/common_voice/cv-valid-train/cv-valid-t...  \n",
       "34896   ../data/common_voice/cv-valid-train/cv-valid-t...  \n",
       "...                                                   ...  \n",
       "119879  ../data/common_voice/cv-valid-train/cv-valid-t...  \n",
       "103694  ../data/common_voice/cv-valid-train/cv-valid-t...  \n",
       "131932  ../data/common_voice/cv-valid-train/cv-valid-t...  \n",
       "146867  ../data/common_voice/cv-valid-train/cv-valid-t...  \n",
       "121958  ../data/common_voice/cv-valid-train/cv-valid-t...  \n",
       "\n",
       "[137043 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/common_voice/cv-valid-train/cv-valid-train/sample-000000.mp3'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0]['file_path']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-4.3655746e-11,  9.0949470e-12,  4.0017767e-11, ...,\n",
       "         1.2503879e-04,  7.3011382e-04,  7.3690247e-04], dtype=float32),\n",
       " 16000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0]['file_path']\n",
    "\n",
    "import librosa \n",
    "\n",
    "librosa.load(df.loc[0]['file_path'], sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv-valid-train/sample-000000.mp3</td>\n",
       "      <td>learn to recognize omens and follow them the o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv-valid-train/sample-000001.mp3</td>\n",
       "      <td>everything in the universe evolved he said</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv-valid-train/sample-000002.mp3</td>\n",
       "      <td>you came so that you could learn about your dr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cv-valid-train/sample-000003.mp3</td>\n",
       "      <td>so now i fear nothing because it was those ome...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cv-valid-train/sample-000004.mp3</td>\n",
       "      <td>if you start your emails with greetings let me...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195771</th>\n",
       "      <td>cv-valid-train/sample-195771.mp3</td>\n",
       "      <td>the englishman said nothing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>england</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195772</th>\n",
       "      <td>cv-valid-train/sample-195772.mp3</td>\n",
       "      <td>the irish man sipped his tea</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195773</th>\n",
       "      <td>cv-valid-train/sample-195773.mp3</td>\n",
       "      <td>what do you know about that</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195774</th>\n",
       "      <td>cv-valid-train/sample-195774.mp3</td>\n",
       "      <td>the phone rang while she was awake</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>us</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195775</th>\n",
       "      <td>cv-valid-train/sample-195775.mp3</td>\n",
       "      <td>among these people were a couple of cyclists a...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195776 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                filename  \\\n",
       "0       cv-valid-train/sample-000000.mp3   \n",
       "1       cv-valid-train/sample-000001.mp3   \n",
       "2       cv-valid-train/sample-000002.mp3   \n",
       "3       cv-valid-train/sample-000003.mp3   \n",
       "4       cv-valid-train/sample-000004.mp3   \n",
       "...                                  ...   \n",
       "195771  cv-valid-train/sample-195771.mp3   \n",
       "195772  cv-valid-train/sample-195772.mp3   \n",
       "195773  cv-valid-train/sample-195773.mp3   \n",
       "195774  cv-valid-train/sample-195774.mp3   \n",
       "195775  cv-valid-train/sample-195775.mp3   \n",
       "\n",
       "                                                     text  up_votes  \\\n",
       "0       learn to recognize omens and follow them the o...         1   \n",
       "1              everything in the universe evolved he said         1   \n",
       "2       you came so that you could learn about your dr...         1   \n",
       "3       so now i fear nothing because it was those ome...         1   \n",
       "4       if you start your emails with greetings let me...         3   \n",
       "...                                                   ...       ...   \n",
       "195771                        the englishman said nothing         1   \n",
       "195772                       the irish man sipped his tea         1   \n",
       "195773                        what do you know about that         1   \n",
       "195774                 the phone rang while she was awake         2   \n",
       "195775  among these people were a couple of cyclists a...         4   \n",
       "\n",
       "        down_votes       age gender   accent  duration  \n",
       "0                0       NaN    NaN      NaN       NaN  \n",
       "1                0       NaN    NaN      NaN       NaN  \n",
       "2                0       NaN    NaN      NaN       NaN  \n",
       "3                0       NaN    NaN      NaN       NaN  \n",
       "4                2       NaN    NaN      NaN       NaN  \n",
       "...            ...       ...    ...      ...       ...  \n",
       "195771           0  thirties   male  england       NaN  \n",
       "195772           0       NaN    NaN      NaN       NaN  \n",
       "195773           0       NaN    NaN      NaN       NaN  \n",
       "195774           0  twenties   male       us       NaN  \n",
       "195775           1       NaN    NaN      NaN       NaN  \n",
       "\n",
       "[195776 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eg = pd.read_csv(\"../data/common_voice/cv-valid-train.csv\")\n",
    "eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
